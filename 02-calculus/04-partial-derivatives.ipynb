{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Partial Derivatives\n",
    "---\n",
    "**Author:** Hamna Munir  \n",
    "**Repository:** Math-for-Machine-Learning  \n",
    "**Section:** Calculus  \n",
    "**Notebook:** 04-partial-derivatives.ipynb\n",
    "\n",
    "**Goal:** Understand partial derivatives for multivariable functions and their role in Machine Learning optimization.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concept",
   "metadata": {},
   "source": [
    "## Concept\n",
    "A partial derivative measures how a multivariable function changes when one variable changes while others remain constant. It is the foundation of gradient-based learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "math-explanation",
   "metadata": {},
   "source": [
    "## Mathematical Explanation\n",
    "For a function f(x, y):\n",
    "\n",
    "### Partial Derivative with respect to x\n",
    "∂f/∂x = derivative of f treating y as constant\n",
    "\n",
    "### Partial Derivative with respect to y\n",
    "∂f/∂y = derivative of f treating x as constant\n",
    "\n",
    "### Example\n",
    "If f(x, y) = x²y + y³\n",
    "\n",
    "∂f/∂x = 2xy\n",
    "∂f/∂y = x² + 3y²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "python-section",
   "metadata": {},
   "source": [
    "## Symbolic Partial Differentiation Using SymPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "\n",
    "x, y = sp.symbols('x y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "partial-example",
   "metadata": {},
   "outputs": [
    {
     \"output_type\": \"execute_result\",
     \"data\": {\n",
     "text/plain\": [\n",
     "2*x*y\n",
     "]\n",
     "},\n",
     "\"metadata\": {},\n",
     "\"execution_count\": 2\n",
     "}\n",
     "   ,\n",
     "   {\n",
     "\"output_type\": \"execute_result\",\n",
     "\"data\": {\n",
     "text/plain\": [\n",
     "x**2 + 3*y**2\n",
     "]\n",
     "},\n",
     "\"metadata\": {},\n",
     "\"execution_count\": 2\n",
     "}\n"
    }
   ],
   "source": [
    "f = x**2 * y + y**3\n",
    "\n",
    "df_dx = sp.diff(f, x)\n",
    "df_dy = sp.diff(f, y)\n",
    "\n",
    "df_dx, df_dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradient-section",
   "metadata": {},
   "source": [
    "## Gradient Vector\n",
    "The gradient is a vector of all partial derivatives.\n",
    "\n",
    "∇f = [∂f/∂x, ∂f/∂y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gradient-code",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Matrix([[2*x*y], [x**2 + 3*y**2]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "gradient = sp.Matrix([df_dx, df_dy])\n",
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization",
   "metadata": {},
   "source": [
    "## Visualization of Partial Derivatives\n",
    "Visualize a 3D surface and gradient directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "f_l = sp.lambdify((x, y), f, 'numpy')\n",
    "\n",
    "x_vals = np.linspace(-3, 3, 50)\n",
    "y_vals = np.linspace(-3, 3, 50)\n",
    "\n",
    "X, Y = np.meshgrid(x_vals, y_vals)\n",
    "Z = f_l(X, Y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
    "ax.set_title(\"Surface: f(x,y) = x²y + y³\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml-connection",
   "metadata": {},
   "source": [
    "## ML Connection\n",
    "Partial derivatives are used in:\n",
    "- Gradient descent\n",
    "- Backpropagation\n",
    "- Multivariable loss functions\n",
    "- Weight updates in neural networks\n",
    "- Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Partial derivatives measure sensitivity to individual variables\n",
    "- Gradients combine partial derivatives\n",
    "- Gradients guide optimization\n",
    "- Fundamental to deep learning training\n",
    "- Enables learning in multidimensional spaces\n",
    "\n",
    "Developed by **Hamna Munir**\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
